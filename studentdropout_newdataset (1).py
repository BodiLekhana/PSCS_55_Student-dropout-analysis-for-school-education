# -*- coding: utf-8 -*-
"""STUDENTDROPOUT-NEWDATASET.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fyX_4_Dq8reu_W6WrZL_O-2Ljjc5YiO8
"""

import pandas as pd
import numpy as np
data=pd.read_csv("dataset.csv")
print(data.shape)
data.head(10)

print(data.describe())
data.info()

# Libraries for implementation and checking performance of ML models

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder          # converts string values to numeric values
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
import matplotlib.pyplot as plt
from sklearn import tree
import seaborn as sns
from sklearn.tree import plot_tree
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc

# Drop the 'Unnamed' columns if they exist in the dataframe
# Identify columns that start with 'Unnamed:'
unnamed_cols = [col for col in data.columns if 'Unnamed:' in col]
if unnamed_cols:
    data = data.drop(columns=unnamed_cols)

# Encode the Target column
label_encoder = LabelEncoder()
data['Target'] = label_encoder.fit_transform(data['Target'])

# Separate features (X) and target (y)
X = data.iloc[:, :-1].values
y = data.iloc[:, -1].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)

from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

param_dist = {
    'n_estimators': randint(50, 300),
    'max_depth': [None] + list(range(5, 31, 5)),
    'min_samples_split': randint(2, 15),
    'min_samples_leaf': randint(1, 10),
    'bootstrap': [True, False]
}

RFmodel = RandomForestClassifier(random_state=42)

random_search = RandomizedSearchCV(
    estimator=RFmodel,
    param_distributions=param_dist,
    n_iter=50,     # number of random combinations
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

random_search.fit(X_train, y_train)

print("Best Parameters:", random_search.best_params_)
print("Best Accuracy:", random_search.best_score_)

best_rf = random_search.best_estimator_

Y_pred = best_rf.predict(X_test)

RFmodel = RandomForestClassifier(bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=3, n_estimators=179)
# estimators - number of decision trees in forest

RFmodel.fit(X_train, y_train)
# used to train machine learning models. It adjusts the parameters of the model based on the provided data.

# to generate predictions for new or unseen data
Y_pred = RFmodel.predict(X_test)

features = data.iloc[:, :-1].columns
class_names = label_encoder.classes_ # Get class names from the label_encoder
plt.figure(figsize=(20,10))  # Set figure size to make the tree more readable
# Plot the first decision tree from the Random Forest model
plot_tree(RFmodel.estimators_[0],
          feature_names=features,
          class_names=class_names,
          filled=True,
          rounded=True)
plt.title("One Decision Tree from the Random Forest")
plt.show()

print("random forest performance")

accuracy = accuracy_score(y_test, Y_pred)
print("Accuracy:", accuracy)
print("---------------------------------------------------")

cm = confusion_matrix(y_test, Y_pred)
print("Confusion Matrix:\n", cm)
print("---------------------------------------------------")

# Classification Report for precision, recall, F1-score
print("Classification Report:\n", classification_report(y_test, Y_pred))

from sklearn.preprocessing import LabelBinarizer

# Binarize the target variable for multiclass ROC
label_binarizer = LabelBinarizer()
y_test_binarized = label_binarizer.fit_transform(y_test)

# Get predicted probabilities for all classes
y_prob = RFmodel.predict_proba(X_test)

plt.figure(figsize=(10, 8))

# Plot ROC curve for each class
for i in range(len(label_binarizer.classes_)):
    class_name = label_binarizer.classes_[i]
    fpr, tpr, thresholds = roc_curve(y_test_binarized[:, i], y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve for {class_name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve for Random Forest\nAccuracy: {:.2f}%'.format(
    accuracy * 100))
plt.legend(loc="lower right")
plt.show()

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

# Parameter grid to search
param_grid = {
    'n_neighbors': [1, 3, 5, 7, 9, 11, 15, 21],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski']
}

knn = KNeighborsClassifier()

grid_search = GridSearchCV(
    estimator=knn,
    param_grid=param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)
print("Best Accuracy:", grid_search.best_score_)

# Best tuned model
best_knn = grid_search.best_estimator_

# Predictions
y_pred = best_knn.predict(X_test)

knn = KNeighborsClassifier(metric='manhattan', n_neighbors=9, weights='uniform')
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)

print("knn performance")

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("---------------------------------------------------")

cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", cm)
print("---------------------------------------------------")

# Classification Report for precision, recall, F1-score
print("Classification Report:\n", classification_report(y_test, y_pred))

from sklearn.preprocessing import LabelBinarizer

# Binarize the target variable for multiclass ROC
label_binarizer = LabelBinarizer()
y_test_binarized = label_binarizer.fit_transform(y_test)

# Get predicted probabilities for all classes
y_prob = knn.predict_proba(X_test)

plt.figure(figsize=(10, 8))

# Plot ROC curve for each class
for i in range(len(label_binarizer.classes_)):
    class_name = label_binarizer.classes_[i]
    fpr, tpr, thresholds = roc_curve(y_test_binarized[:, i], y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve for {class_name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve for kNN\nAccuracy: {:.2f}%'.format(
    accuracy * 100))
plt.legend(loc="lower right")
plt.show()

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

# Model object
LRmodel = LogisticRegression()

# Hyperparameter grid
param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],        # regularization strength
    'penalty': ['l1', 'l2'],                    # regularization type
    'solver': ['liblinear', 'saga'],            # solvers that support L1
    'max_iter': [100, 200, 500, 1000]
}

# Grid search
grid_search = GridSearchCV(
    estimator=LRmodel,
    param_grid=param_grid,
    cv=5,
    scoring='accuracy',
    verbose=1,
    n_jobs=-1
)

# Fit on training data
grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)
print("Best CV Accuracy:", grid_search.best_score_)

# Use the best model
best_LR = grid_search.best_estimator_

# Predict
y_pred = best_LR.predict(X_test)

LRmodel = LogisticRegression(C=1, max_iter=5000, penalty='l2', solver='saga')
LRmodel.fit(X_train, y_train)

y_pred = LRmodel.predict(X_test)

print("linear regression performance")

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("---------------------------------------------------")

cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", cm)
print("---------------------------------------------------")

# Classification Report for precision, recall, F1-score
print("Classification Report:\n", classification_report(y_test, y_pred))

from sklearn.preprocessing import LabelBinarizer

# Binarize the target variable for multiclass ROC
label_binarizer = LabelBinarizer()
y_test_binarized = label_binarizer.fit_transform(y_test)

# Get predicted probabilities for all classes
y_prob = LRmodel.predict_proba(X_test)

plt.figure(figsize=(10, 8))

# Plot ROC curve for each class
for i in range(len(label_binarizer.classes_)):
    class_name = label_binarizer.classes_[i]
    fpr, tpr, thresholds = roc_curve(y_test_binarized[:, i], y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve for {class_name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve for Logistic Regression\nAccuracy: {:.2f}%'.format(
    accuracy * 100))
plt.legend(loc="lower right")
plt.show()

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

# Define the model
dt = DecisionTreeClassifier(criterion="entropy", random_state=100)

# Hyperparameter grid
param_grid = {
    "max_depth": [2, 3, 4, 5, 6, 8, 10],
    "min_samples_leaf": [1, 2, 3, 5, 10],
    "min_samples_split": [2, 5, 10, 20],
    "max_features": [None, "sqrt", "log2"]
}

# Grid Search
grid_search = GridSearchCV(estimator=dt,
                           param_grid=param_grid,
                           cv=5,
                           scoring="accuracy")

grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)

# Predict using best model
best_dt = grid_search.best_estimator_
y_pred = best_dt.predict(X_test)

clf_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=8, max_features=None, min_samples_leaf=10, min_samples_split=2, random_state=100)

clf_entropy.fit(X_train, y_train)

Y_pred = clf_entropy.predict(X_test)

print("decision tree performance using entropy")

accuracy = accuracy_score(y_test, Y_pred)
print("Accuracy:", accuracy)
print("---------------------------------------------------")

cm = confusion_matrix(y_test, Y_pred)
print("Confusion Matrix:\n", cm)
print("---------------------------------------------------")

# Classification Report for precision, recall, F1-score
print("Classification Report:\n", classification_report(y_test, Y_pred))

from sklearn.preprocessing import LabelBinarizer

# Binarize the target variable for multiclass ROC
label_binarizer = LabelBinarizer()
y_test_binarized = label_binarizer.fit_transform(y_test)

# Get predicted probabilities for all classes
y_prob = clf_entropy.predict_proba(X_test)

plt.figure(figsize=(10, 8))

# Plot ROC curve for each class
for i in range(len(label_binarizer.classes_)):
    class_name = label_binarizer.classes_[i]
    fpr, tpr, thresholds = roc_curve(y_test_binarized[:, i], y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve for {class_name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve for Decision Tree\nAccuracy: {:.2f}%'.format(
    accuracy * 100))
plt.legend(loc="lower right")
plt.show()

import shap
explainer = shap.Explainer(clf_entropy)
shap_values = explainer(X_test)

shap.summary_plot(shap_values, X_test)

from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import GridSearchCV

nb = GaussianNB()

param_grid = {
    "var_smoothing": [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]
}

grid_search = GridSearchCV(nb, param_grid, cv=5, scoring="accuracy")
grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)

best_nb = grid_search.best_estimator_
y_pred = best_nb.predict(X_test)

nb_classifier = GaussianNB(var_smoothing= 0.0001)

nb_classifier.fit(X_train, y_train)

y_pred = nb_classifier.predict(X_test)

print("naive bayesian performance")

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("---------------------------------------------------")

cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", cm)
print("---------------------------------------------------")

# Classification Report for precision, recall, F1-score
print("Classification Report:\n", classification_report(y_test, y_pred))

from sklearn.preprocessing import LabelBinarizer

# Binarize the target variable for multiclass ROC
label_binarizer = LabelBinarizer()
y_test_binarized = label_binarizer.fit_transform(y_test)

# Get predicted probabilities for all classes
y_prob = nb_classifier.predict_proba(X_test)

plt.figure(figsize=(10, 8))

# Plot ROC curve for each class
for i in range(len(label_binarizer.classes_)):
    class_name = label_binarizer.classes_[i]
    fpr, tpr, thresholds = roc_curve(y_test_binarized[:, i], y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve for {class_name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve for Naive Bayes\nAccuracy: {:.2f}%'.format(
    accuracy * 100))
plt.legend(loc="lower right")
plt.show()

from sklearn.model_selection import RandomizedSearchCV
import numpy as np

svm_model = SVC(random_state=42)

param_dist = {
    "kernel": ["linear", "rbf", "poly", "sigmoid"],
    "C": np.logspace(-2, 2, 20),
    "gamma": ["scale", "auto"] + list(np.logspace(-3, 1, 10)),
    "degree": [2, 3, 4]
}

random_search = RandomizedSearchCV(
    svm_model,
    param_dist,
    n_iter=20,
    cv=5,
    scoring="accuracy",
    n_jobs=-1
)

random_search.fit(X_train, y_train)

print("Best Parameters:", random_search.best_params_)
print("Best CV Score:", random_search.best_score_)

best_svm = random_search.best_estimator_
y_pred = best_svm.predict(X_test)

svm = SVC(kernel='linear', C=1.0, random_state=42, probability=True)
# kernel='linear': uses a linear kernel for classification
# C=1.0: regularization parameter to control margin vs misclassification
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)

print("SVM performance")

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("---------------------------------------------------")

cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", cm)
print("---------------------------------------------------")

# Classification Report for precision, recall, F1-score
print("Classification Report:\n", classification_report(y_test, y_pred))

from sklearn.preprocessing import LabelBinarizer

# Binarize the target variable for multiclass ROC
label_binarizer = LabelBinarizer()
y_test_binarized = label_binarizer.fit_transform(y_test)

# Get predicted probabilities for all classes
y_prob = svm.predict_proba(X_test)

plt.figure(figsize=(10, 8))

# Plot ROC curve for each class
for i in range(len(label_binarizer.classes_)):
    class_name = label_binarizer.classes_[i]
    fpr, tpr, thresholds = roc_curve(y_test_binarized[:, i], y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve for {class_name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve for SVM\nAccuracy: {:.2f}%'.format(
    accuracy * 100))
plt.legend(loc="lower right")
plt.show()

from sklearn.model_selection import RandomizedSearchCV
import numpy as np
from sklearn.ensemble import GradientBoostingClassifier

gb = GradientBoostingClassifier(random_state=42)

param_dist = {
    "n_estimators": np.arange(50, 300, 50),
    "learning_rate": np.linspace(0.01, 0.3, 20),
    "max_depth": np.arange(2, 6),
    "subsample": np.linspace(0.6, 1.0, 5),
    "min_samples_split": np.arange(2, 10),
    "min_samples_leaf": np.arange(1, 5)
}

random_search = RandomizedSearchCV(
    gb,
    param_dist,
    n_iter=25,
    cv=5,
    scoring="accuracy",
    n_jobs=-1
)

random_search.fit(X_train, y_train)

print("Best Parameters:", random_search.best_params_)
print("Best CV Score:", random_search.best_score_)

best_gb = random_search.best_estimator_
y_pred = best_gb.predict(X_test)

gb_clf = GradientBoostingClassifier(subsample=np.float64(0.7), n_estimators=np.int64(150), min_samples_split=np.int64(5), min_samples_leaf=np.int64(3), max_depth=np.int64(4), learning_rate=np.float64(0.04052631578947368), random_state=42)
gb_clf.fit(X_train, y_train)
y_pred = gb_clf.predict(X_test)

print("gradient boosting performance")

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("---------------------------------------------------")

cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", cm)
print("---------------------------------------------------")

# Classification Report for precision, recall, F1-score
print("Classification Report:\n", classification_report(y_test, y_pred))

from sklearn.preprocessing import LabelBinarizer

# Binarize the target variable for multiclass ROC
label_binarizer = LabelBinarizer()
y_test_binarized = label_binarizer.fit_transform(y_test)

# Get predicted probabilities for all classes
y_prob = gb_clf.predict_proba(X_test)

plt.figure(figsize=(10, 8))

# Plot ROC curve for each class
for i in range(len(label_binarizer.classes_)):
    class_name = label_binarizer.classes_[i]
    fpr, tpr, thresholds = roc_curve(y_test_binarized[:, i], y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve for {class_name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve for Gradient Boosting\nAccuracy: {:.2f}%'.format(
    accuracy * 100))
plt.legend(loc="lower right")
plt.show()

df_new = pd.get_dummies(data)
corr_matrix = df_new.corr()

plt.figure(figsize=(32, 24))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix')
plt.show()