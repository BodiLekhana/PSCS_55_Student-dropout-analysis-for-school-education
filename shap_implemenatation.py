# -*- coding: utf-8 -*-
"""SHAP implemenatation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14B1IgimO5oiq2wlBhPLJVarpQWcvYSNy
"""

import shap
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder

data_for_shap = pd.read_csv("dataset.csv")

X_shap = data_for_shap.drop('Target', axis=1)
y_shap = data_for_shap['Target']

label_encoder = LabelEncoder()
y_shap_encoded = label_encoder.fit_transform(y_shap)

X_train_shap, X_test_shap, y_train_shap, y_test_shap = train_test_split(X_shap, y_shap_encoded, test_size=0.2, random_state=42)

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM": SVC(kernel='linear', C=1.0, random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth= 3, random_state=42),
    "Naive Bayes": GaussianNB(),
    "Decision Tree": DecisionTreeClassifier(criterion="entropy", random_state=100, max_depth=3, min_samples_leaf=5),
    "KNN": KNeighborsClassifier(n_neighbors=5)
}

for name, model in models.items():
    model.fit(X_train_shap, y_train_shap)
    print(f"{name} trained successfully.")

# SHAP Analysis
for name, model in models.items():
    print(f"\nExplaining {name}...")

    if name in ["Gradient Boosting", "Naive Bayes", "KNN"]:
        print(f"Skipping SHAP explanation for {name} due to multi-class limitation or unsupported explainer type.")
        continue # Skip to the next model

    if name in ["Random Forest", "Decision Tree"]: # Using TreeExplainer for tree-based models that support multi-class
        explainer = shap.TreeExplainer(model)
        # For multi-class classification, shap_values can be a list of arrays
        shap_values = explainer.shap_values(X_test_shap)
    else:  # Using LinearExplainer for linear models or others where appropriate
        # LinearExplainer works well for models where feature effects are additive
        # For non-linear models, KernelExplainer might be more appropriate but is computationally intensive.
        explainer = shap.LinearExplainer(model, X_train_shap, feature_perturbation="interventional")
        shap_values = explainer.shap_values(X_test_shap)

    plt.figure(figsize=(20, 16))
    shap.summary_plot(shap_values, X_test_shap, show=False)
    plt.title(f"SHAP Summary Plot for {name}")
    plt.tight_layout() # Adjust layout to prevent labels overlapping
    plt.show()

    # SHAP Bar Plot (average feature importance)
    plt.figure(figsize=(20, 16))
    shap.summary_plot(shap_values, X_test_shap, plot_type="bar", show=False)
    plt.title(f"Feature Importance (SHAP Bar Plot) - {name}")
    plt.tight_layout() # Adjust layout to prevent labels overlapping
    plt.show()

print("SHAP analysis completed for all models.")

