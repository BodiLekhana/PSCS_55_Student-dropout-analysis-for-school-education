# -*- coding: utf-8 -*-
"""LIME implementation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G9v8Fh_vEbzNjXw-zCvHDlq56lpdah0Z
"""

pip install lime scikit-learn

import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

from lime.lime_tabular import LimeTabularExplainer

data = pd.read_csv("dataset.csv")
X = data.drop('Target', axis=1)
y = data['Target']
feature_names = X.columns.tolist()
class_names = y.unique().tolist()

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "KNN": KNeighborsClassifier(),
    "Naive Bayes": GaussianNB(),
    "Gradient Boosting": GradientBoostingClassifier(),
    "SVM": SVC(probability=True)
}

for name, model in models.items():
    model.fit(X_train, y_train)
    print(f"{name} trained successfully!")

explainer = LimeTabularExplainer(
    training_data=X_train.values,
    feature_names=feature_names,
    class_names=class_names,
    mode="classification"
)

index = 5
instance = X_test.iloc[index]

lime_dict = {}

for name, model in models.items():
    exp = explainer.explain_instance(instance, model.predict_proba)
    contrib = dict(exp.as_list())
    lime_dict[name] = contrib

lime_df = pd.DataFrame(lime_dict).fillna(0)

print(lime_df)

import matplotlib.pyplot as plt

plt.figure(figsize=(16, 8))
lime_df.plot(kind="bar", figsize=(14, 6))
plt.title("LIME Feature Contribution Comparison Across ML Models")
plt.xlabel("Interpretable Features")
plt.ylabel("Contribution Weight")
plt.xticks(rotation=45, ha="right")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt

for name, model in models.items():

    # Generate LIME explanation
    exp = explainer.explain_instance(instance, model.predict_proba)

    # Convert explanation (list of tuples) to dict → then to DataFrame
    contrib_dict = dict(exp.as_list())
    keys = list(contrib_dict.keys())
    values = list(contrib_dict.values())

    # Create individual plot
    plt.figure(figsize=(10, 5))
    plt.barh(keys, values)

    plt.title(f"LIME Feature Contributions – {name}")
    plt.xlabel("Contribution Weight")
    plt.ylabel("Features")

    # Add grid for readability
    plt.grid(axis='x', linestyle='--', alpha=0.6)

    # Tight layout to avoid cutting labels
    plt.tight_layout()

    # Show the plot
    plt.show()

    # OPTIONAL: Save image
    # plt.savefig(f"lime_{name.replace(' ', '_')}.png")