# -*- coding: utf-8 -*-
"""studentdropout-nn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uIylFm1YqakVZi9I0hXk4xVh4AgGPpWD
"""

import keras
from numpy import loadtxt
from keras.models import Sequential
from keras.layers import Dense
import pandas as pd
df = pd.read_csv("dataset.csv")

print(df.dtypes)

# Attempt to convert non-numeric columns to numeric, coercing errors and filling NaNs
for col in df.columns:
    if df[col].dtype == 'object':
        try:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        except:
            pass # Handle columns that cannot be converted if necessary

df.fillna(0, inplace=True)

X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values


model = Sequential()

model.add(Dense(12, input_dim=34, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(X, y, epochs=150, batch_size=16)

_, accuracy = model.evaluate(X, y)
print('Accuracy: %.2f' % (accuracy*100))

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report
from keras.models import Sequential
from keras.layers import Dense
from matplotlib import pyplot as plt
import numpy as np

file_path = "dataset.csv"
data = pd.read_csv(file_path)

print("Dataset shape:", data.shape)
print(data.head())

label_encoders = {}
for col in data.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
    label_encoders[col] = le


target_col = 'Target'
X = data.drop(target_col, axis=1)
y = data[target_col]

# Ensure the target variable 'y' is strictly binary (0 or 1) for binary classification.
# The error "Target is multiclass but average='binary'" suggests that 'y' contains
# more than two unique labels, or two labels that are not 0 and 1 (e.g., 0 and 2).
# Based on the kernel state, 'y' contains 0 and 2. To align with a binary classification
# model (sigmoid output, binary_crossentropy loss) and standard binary evaluation metrics,
# we remap the target values. Assuming '0' and '2' are the two primary labels and we
# want to classify between them, we map '2' to '1'.

if 2 in y.unique() and 0 in y.unique():
    y = y.replace(2, 1)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

trainX, testX, trainy, testy = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

model = Sequential()
model.add(Dense(100, input_shape=(trainX.shape[1],), activation='relu'))
model.add(Dense(50, activation='relu'))
model.add(Dense(1, activation='sigmoid'))  # sigmoid for binary classification

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, batch_size=32, verbose=1)

train_loss, train_acc = model.evaluate(trainX, trainy, verbose=0)
test_loss, test_acc = model.evaluate(testX, testy, verbose=0)
print('\nTrain Accuracy: %.3f, Test Accuracy: %.3f' % (train_acc, test_acc))

y_pred_probs = model.predict(testX)
y_pred = (y_pred_probs > 0.5).astype(int)  # convert probabilities to binary

# Compute metrics
# Now testy should be strictly 0 or 1 due to the remapping, so average='binary' is appropriate.
precision = precision_score(testy, y_pred)
recall = recall_score(testy, y_pred)
f1 = f1_score(testy, y_pred)

print("\nPrecision: %.3f" % precision)
print("Recall: %.3f" % recall)
print("F1-Score: %.3f" % f1)

print("\nClassification Report:\n", classification_report(testy, y_pred))

plt.figure(figsize=(10, 6))

# Loss
plt.subplot(2, 1, 1)
plt.title('Loss During Training')
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()

# Accuracy
plt.subplot(2, 1, 2)
plt.title('Accuracy During Training')
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

from sklearn.metrics import roc_curve, roc_auc_score

fpr, tpr, thresholds = roc_curve(testy, y_pred_probs)
roc_auc = roc_auc_score(testy, y_pred_probs)

plt.figure(figsize=(6, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.3f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve for Neural Network')
plt.legend()
plt.show()

# -----------------------------------------------------
# 8. Plot Training History
# -----------------------------------------------------
plt.figure(figsize=(10, 6))

# Loss
plt.subplot(2, 1, 1)
plt.title('Loss During Training')
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()

# Accuracy
plt.subplot(2, 1, 2)
plt.title('Accuracy During Training')
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()

plt.tight_layout()
plt.show()